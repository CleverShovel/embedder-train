{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import os\n",
    "from dataclasses import dataclass, field\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import polars as pl\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from sentence_transformers import (\n",
    "    SentenceTransformer,\n",
    "    SentenceTransformerTrainer,\n",
    "    SentenceTransformerTrainingArguments,\n",
    ")\n",
    "from sentence_transformers.evaluation import TripletEvaluator\n",
    "from sentence_transformers.losses import (\n",
    "    BatchAllTripletLoss,\n",
    "    BatchHardTripletLoss,\n",
    "    BatchSemiHardTripletLoss,  # надо попробовать этот лосс\n",
    ")\n",
    "from sentence_transformers.losses.BatchHardTripletLoss import (\n",
    "    BatchHardTripletLossDistanceFunction,\n",
    ")\n",
    "from sentence_transformers.training_args import BatchSamplers\n",
    "from sentence_transformers.util import dot_score\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_cosine_with_hard_restarts_schedule_with_warmup\n",
    "\n",
    "\n",
    "def dot_distance(embeddings: torch.Tensor) -> torch.Tensor:\n",
    "    return 1 - dot_score(embeddings, embeddings)\n",
    "\n",
    "\n",
    "os.environ[\"HTTPS_PROXY\"] = \"http://proxy-server.sovcombank.group:3128\"\n",
    "os.environ[\"HTTP_PROXY\"] = \"http://proxy-server.sovcombank.group:3128\"\n",
    "os.environ[\"NO_PROXY\"] = \"localhost,127.0.0.1,.sovcombank.group\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    # Columns\n",
    "    text_col: str = \"text_col\"\n",
    "    label_col: str = \"label_col\"\n",
    "    preprocessed_text_col: str = \"preprocessed_text\"\n",
    "    preprocessed_label_col: str = \"preprocessed_label\"\n",
    "\n",
    "    # Paths\n",
    "    data_volume: Path = Path(\".\")\n",
    "    data_folds_path: Path = Path(\"./data/dataset-1\")\n",
    "    base_model: str = \"sergeyzh/rubert-tiny-turbo\"\n",
    "    artifacts_dir: Path = Path(\"./artifacts\")\n",
    "\n",
    "    # Model parameters\n",
    "    max_seq_length: int = 512\n",
    "\n",
    "    # Training parameters\n",
    "    distance_metric: str = \"cosine\"  # or \"dot\"\n",
    "    loss_func: str = \"BatchSemiHardTripletLoss\"\n",
    "    margin: float = 5.0\n",
    "    seed: int = 545454663\n",
    "    max_steps: int = 1000\n",
    "    log_steps: int = 100\n",
    "    per_device_train_batch_size: int = 256\n",
    "    per_device_eval_batch_size: int = 32\n",
    "    learning_rate: float = 2e-5\n",
    "    warmup_ratio: float = 0.1\n",
    "    gradient_checkpointing: bool = False\n",
    "    metric_for_best_model: str = \"eval_loss\"\n",
    "    lr_scheduler_kwargs: dict = field(init=False)\n",
    "    torch_compile: bool = True\n",
    "    dataloader_pin_memory: bool = True\n",
    "    use_cpu: bool = False\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.lr_scheduler_kwargs = {\n",
    "            \"num_warmup_steps\": int(self.warmup_ratio * self.max_steps),\n",
    "            \"num_training_steps\": self.max_steps,\n",
    "            \"num_cycles\": 10,\n",
    "            \"last_epoch\": -1,\n",
    "        }\n",
    "\n",
    "        self.eval_data_path = Path(\"./data/dataset-1/eval\")\n",
    "        self.train_path = Path(\"./data/dataset-1/train_data.parquet\")\n",
    "        self.val_path = Path(\"./data/dataset-1/val_data.parquet\")\n",
    "        self.test_path = Path(\"./data/dataset-1/test_data.parquet\")\n",
    "        self.val_triplets_path = Path(\"./data/dataset-1/eval/val_triplets.parquet\")\n",
    "        self.test_triplets_path = Path(\"./data/dataset-1/eval/test_triplets.parquet\")\n",
    "\n",
    "        self.current_time_str = datetime.now().strftime(\"%Y_%m_%d-%I_%M_%S_%p\")\n",
    "        self.experiment_name = f\"{self.current_time_str}_{Path(self.base_model).stem}\"\n",
    "        self.outputs_dir = self.artifacts_dir / self.experiment_name\n",
    "        self.checkpoints_dir = self.artifacts_dir / Path(self.base_model).stem\n",
    "\n",
    "        self.result_dir = self.outputs_dir / \"weights\"\n",
    "        self.metrics_dir = self.outputs_dir / \"metrics\"\n",
    "        self.logs_dir = self.outputs_dir / \"logs\"\n",
    "\n",
    "        self.outputs_dir.mkdir(parents=True, exist_ok=True)\n",
    "        self.checkpoints_dir.mkdir(parents=True, exist_ok=True)\n",
    "        self.result_dir.mkdir(parents=True, exist_ok=True)\n",
    "        self.metrics_dir.mkdir(parents=True, exist_ok=True)\n",
    "        self.logs_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Гиперпараметры, влияющие на потребляемую память и на скорость обучения:\n",
    "1. gradient_checkpointing\n",
    "3. per_device_train_batch_size желательно побольше >=128\n",
    "4. per_device_eval_batch_size\n",
    "5. distance_metric, cosine или dot\n",
    "6. torch_compile\n",
    "7. dataloader_pin_memory\n",
    "8. max_seq_length\n",
    "\n",
    "влияющие на качество обучения:\n",
    "1. предобработка датасета\n",
    "1. max_steps\n",
    "2. warmup_ratio\n",
    "3. learning_rate\n",
    "7. loss_func, margin\n",
    "4. per_device_train_batch_size\n",
    "6. distance_metric\n",
    "9. metric_for_best_model\n",
    "5. max_seq_length\n",
    "\n",
    "Тут подробно описаны все гиперпараметры, влияюшие на обучение, для библиотеки transformers \n",
    "https://huggingface.co/docs/transformers/perf_train_gpu_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_datasets(\n",
    "    train_path,\n",
    "    val_path,\n",
    "    test_path,\n",
    "    text_col=\"text\",\n",
    "    label_col=\"label\",\n",
    "    preprocessed_label_col=\"label_\",\n",
    "    min_num_examples_threshold=2,\n",
    "):\n",
    "    train_df = pl.read_parquet(train_path)\n",
    "    val_df = pl.read_parquet(val_path)\n",
    "    test_df = pl.read_parquet(test_path)\n",
    "\n",
    "    classes = set(\n",
    "        [\n",
    "            *train_df[label_col].unique().to_list(),\n",
    "            *val_df[label_col].unique().to_list(),\n",
    "            *test_df[label_col].unique().to_list(),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    inverse_mapping = {c: idx for idx, c in enumerate(classes)}\n",
    "\n",
    "    train_df = train_df.with_columns(\n",
    "        pl.col(label_col)\n",
    "        .replace(inverse_mapping, return_dtype=pl.Int32)\n",
    "        .alias(preprocessed_label_col)\n",
    "    )\n",
    "    val_df = val_df.with_columns(\n",
    "        pl.col(label_col)\n",
    "        .replace(inverse_mapping, return_dtype=pl.Int32)\n",
    "        .alias(preprocessed_label_col)\n",
    "    )\n",
    "    test_df = test_df.with_columns(\n",
    "        pl.col(label_col)\n",
    "        .replace(inverse_mapping, return_dtype=pl.Int32)\n",
    "        .alias(preprocessed_label_col)\n",
    "    )\n",
    "\n",
    "    min_num_examples_threshold = 2\n",
    "\n",
    "    train_df = train_df.filter(\n",
    "        pl.col(label_col).count().over(label_col) >= min_num_examples_threshold\n",
    "    )\n",
    "\n",
    "    def process_hf_dataset(dataset):\n",
    "        dataset = dataset.select_columns([text_col, preprocessed_label_col])\n",
    "        dataset = dataset.rename_columns(\n",
    "            {text_col: \"sentence\", preprocessed_label_col: \"label\"}\n",
    "        )\n",
    "        return dataset\n",
    "\n",
    "    train_dataset = process_hf_dataset(Dataset.from_polars(train_df))\n",
    "    val_dataset = process_hf_dataset(Dataset.from_polars(val_df))\n",
    "    test_dataset = process_hf_dataset(Dataset.from_polars(test_df))\n",
    "\n",
    "    return {\"train\": train_dataset, \"val\": val_dataset, \"test\": test_dataset}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_evaluator(triplets_path, fold=\"val\", batch_size=32):\n",
    "    triplets_df = pl.read_parquet(triplets_path)\n",
    "    anchors = triplets_df[\"anchors\"].to_list()\n",
    "    positives = triplets_df[\"positives\"].to_list()\n",
    "    negatives = triplets_df[\"negatives\"].to_list()\n",
    "\n",
    "    evaluator = TripletEvaluator(\n",
    "        anchors=anchors,\n",
    "        positives=positives,\n",
    "        negatives=negatives,\n",
    "        name=f\"ffl_triplet_{fold}\",\n",
    "        batch_size=batch_size,\n",
    "        main_distance_function=\"cosine\",\n",
    "    )\n",
    "\n",
    "    return evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(base_model, max_seq_length=512):\n",
    "    model = SentenceTransformer(base_model)\n",
    "    model.max_seq_length = max_seq_length\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_distance_func(distance_metric):\n",
    "    distance_func = BatchHardTripletLossDistanceFunction.cosine_distance\n",
    "    if distance_metric == \"dot\":\n",
    "        distance_func = dot_distance\n",
    "    return distance_func\n",
    "\n",
    "\n",
    "def prepare_loss(model, loss_name, **args):\n",
    "    if loss_name == \"BatchSemiHardTripletLoss\":\n",
    "        distance_metric = args[\"distance_metric\"]\n",
    "        margin = args[\"margin\"]\n",
    "        loss = BatchSemiHardTripletLoss(\n",
    "            model, distance_metric=distance_metric, margin=margin\n",
    "        )\n",
    "    elif loss_name == \"BatchHardTripletLoss\":\n",
    "        distance_metric = args[\"distance_metric\"]\n",
    "        margin = args[\"margin\"]\n",
    "        loss = BatchHardTripletLoss(\n",
    "            model, distance_metric=distance_metric, margin=margin\n",
    "        )\n",
    "    elif loss_name == \"BatchHardSoftMarginTripletLoss\":\n",
    "        distance_metric = args[\"distance_metric\"]\n",
    "        loss = BatchHardTripletLoss(model, distance_metric=distance_metric)\n",
    "    elif loss_name == \"BatchAllTripletLoss\":\n",
    "        distance_metric = args[\"distance_metric\"]\n",
    "        margin = args[\"margin\"]\n",
    "        loss = BatchAllTripletLoss(\n",
    "            model, distance_metric=distance_metric, margin=margin\n",
    "        )\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    checkpoints_dir=\"checkpoints/\",\n",
    "    max_steps=100,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    learning_rate=2e-5,\n",
    "    warmup_ratio=0.1,\n",
    "    log_steps=50,\n",
    "    seed=42,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    gradient_checkpointing=False,\n",
    "    torch_compile=False,\n",
    "    dataloader_pin_memory=True,\n",
    "    model=None,\n",
    "    train_dataset=None,\n",
    "    val_dataset=None,\n",
    "    loss=None,\n",
    "    val_evaluator=None,\n",
    "    optimizer=None,\n",
    "    lr_scheduler=None,\n",
    "    use_cpu=False,\n",
    "):\n",
    "    train_args = SentenceTransformerTrainingArguments(\n",
    "        # Required parameter:\n",
    "        output_dir=checkpoints_dir,\n",
    "        # Optional training parameters:\n",
    "        max_steps=max_steps,\n",
    "        per_device_train_batch_size=per_device_train_batch_size,\n",
    "        per_device_eval_batch_size=per_device_eval_batch_size,\n",
    "        learning_rate=learning_rate,\n",
    "        warmup_ratio=warmup_ratio,\n",
    "        fp16=not use_cpu,  # Set to False if you get an error that your GPU can't run on FP16\n",
    "        bf16=False,  # Set to True if you have a GPU that supports BF16\n",
    "        batch_sampler=BatchSamplers.NO_DUPLICATES,  # losses that use \"in-batch negatives\" benefit from no duplicates\n",
    "        # Optional tracking/debugging parameters:\n",
    "        eval_strategy=\"steps\",\n",
    "        eval_steps=log_steps,\n",
    "        save_strategy=\"steps\",\n",
    "        save_steps=log_steps,\n",
    "        save_total_limit=2,\n",
    "        logging_steps=log_steps,\n",
    "        run_name=\"train-experiment\",\n",
    "        report_to=\"none\",\n",
    "        use_cpu=use_cpu,\n",
    "        seed=seed,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=metric_for_best_model,\n",
    "        greater_is_better=True,\n",
    "        dataloader_num_workers=4,\n",
    "        gradient_checkpointing=gradient_checkpointing,\n",
    "        torch_compile=torch_compile,\n",
    "        dataloader_pin_memory=dataloader_pin_memory,\n",
    "    )\n",
    "\n",
    "    trainer = SentenceTransformerTrainer(\n",
    "        model=model,\n",
    "        args=train_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        loss=loss,\n",
    "        evaluator=val_evaluator,\n",
    "        optimizers=(optimizer, lr_scheduler),\n",
    "    )\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_experiment_params(config, result_dir):\n",
    "    dataset_params = dict(\n",
    "        text_col=config.text_col,\n",
    "        label_col=config.label_col,\n",
    "        preprocessed_text_col=config.preprocessed_text_col,\n",
    "        preprocessed_label_col=config.preprocessed_label_col,\n",
    "        data_volume=str(config.data_volume),\n",
    "        dataset_path=str(config.dataset_path),\n",
    "        data_folds_path=str(config.data_folds_path),\n",
    "        eval_data_path=str(config.eval_data_path),\n",
    "    )\n",
    "\n",
    "    model_params = dict(\n",
    "        base_model=config.base_model, max_seq_length=config.max_seq_length\n",
    "    )\n",
    "\n",
    "    train_params = dict(\n",
    "        distance_metric=config.distance_metric,\n",
    "        loss=config.loss_func,\n",
    "        margin=config.margin,\n",
    "        max_steps=config.max_steps,\n",
    "        per_device_train_batch_size=config.per_device_train_batch_size,\n",
    "        per_device_eval_batch_size=config.per_device_eval_batch_size,\n",
    "        learning_rate=config.learning_rate,\n",
    "        warmup_ratio=config.warmup_ratio,\n",
    "        seed=config.seed,\n",
    "        gradient_checkpointing=config.gradient_checkpointing,\n",
    "        lr_scheduler_kwargs=config.lr_scheduler_kwargs,\n",
    "        torch_compile=config.torch_compile,\n",
    "        dataloader_pin_memory=config.dataloader_pin_memory,\n",
    "    )\n",
    "\n",
    "    params = {\n",
    "        \"dataset_params\": dataset_params,\n",
    "        \"train_params\": train_params,\n",
    "        \"model_params\": model_params,\n",
    "    }\n",
    "\n",
    "    result_dir = Path(result_dir)\n",
    "    with open(result_dir / \"experiment_params.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(params, f)\n",
    "\n",
    "\n",
    "def evaluate_and_save_results(model, evaluator, fold=\"test\", metrics_dir=\"metrics/\"):\n",
    "    metrics_dir = Path(metrics_dir)\n",
    "    results = evaluator(model)\n",
    "    test_metrics = dict(results)\n",
    "    with open(metrics_dir / f\"{fold}_metrics.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(test_metrics, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config()\n",
    "\n",
    "datasets = prepare_datasets(\n",
    "    config.train_path,\n",
    "    config.val_path,\n",
    "    config.test_path,\n",
    "    text_col=config.text_col,\n",
    "    label_col=config.label_col,\n",
    "    preprocessed_label_col=config.preprocessed_label_col,\n",
    "    min_num_examples_threshold=2,\n",
    ")\n",
    "\n",
    "if config.eval_data_path.exists() and any(config.eval_data_path.iterdir()):\n",
    "    val_evaluator = prepare_evaluator(\n",
    "        config.val_triplets_path,\n",
    "        fold=\"val\",\n",
    "        batch_size=config.per_device_eval_batch_size,\n",
    "    )\n",
    "\n",
    "    test_evaluator = prepare_evaluator(\n",
    "        config.test_triplets_path,\n",
    "        fold=\"test\",\n",
    "        batch_size=config.per_device_eval_batch_size,\n",
    "    )\n",
    "else:\n",
    "    val_evaluator = None\n",
    "    test_evaluator = None\n",
    "\n",
    "logging.basicConfig(\n",
    "    filename=str(config.logs_dir / f\"{config.experiment_name}_script.log\"),\n",
    "    level=logging.INFO,\n",
    ")\n",
    "\n",
    "model = init_model(config.base_model, max_seq_length=config.max_seq_length)\n",
    "distance_metric = get_distance_func(config.distance_metric)\n",
    "loss = prepare_loss(\n",
    "    model, config.loss_func, distance_metric=distance_metric, margin=config.margin\n",
    ")\n",
    "optimizer = AdamW(model.parameters(), lr=config.learning_rate, fused=True)\n",
    "lr_scheduler = get_cosine_with_hard_restarts_schedule_with_warmup(\n",
    "    optimizer, **config.lr_scheduler_kwargs\n",
    ")\n",
    "\n",
    "train(\n",
    "    checkpoints_dir=config.checkpoints_dir,\n",
    "    max_steps=config.max_steps,\n",
    "    per_device_train_batch_size=config.per_device_train_batch_size,\n",
    "    per_device_eval_batch_size=config.per_device_eval_batch_size,\n",
    "    learning_rate=config.learning_rate,\n",
    "    warmup_ratio=config.warmup_ratio,\n",
    "    seed=config.seed,\n",
    "    gradient_checkpointing=config.gradient_checkpointing,\n",
    "    log_steps=config.log_steps,\n",
    "    metric_for_best_model=config.metric_for_best_model,\n",
    "    torch_compile=config.torch_compile,\n",
    "    dataloader_pin_memory=config.dataloader_pin_memory,\n",
    "    model=model,\n",
    "    train_dataset=datasets[\"train\"],\n",
    "    val_dataset=datasets[\"val\"],\n",
    "    loss=loss,\n",
    "    val_evaluator=val_evaluator,\n",
    "    optimizer=optimizer,\n",
    "    lr_scheduler=lr_scheduler,\n",
    "    use_cpu=config.use_cpu,\n",
    ")\n",
    "\n",
    "model.save_pretrained(str(config.result_dir))\n",
    "\n",
    "save_experiment_params(config, config.result_dir)\n",
    "\n",
    "if test_evaluator is not None:\n",
    "    evaluate_and_save_results(model, test_evaluator, metrics_dir=config.metrics_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
